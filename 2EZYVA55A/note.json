{
  "paragraphs": [
    {
      "text": "%md\n### Cosa fare con i valori nulli nel dataframe",
      "user": "anonymous",
      "dateUpdated": "2020-02-12 00:23:55.451",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eCosa fare con i valori nulli nel dataframe\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581463407961_-35874583",
      "id": "20200212-002327_1874230922",
      "dateCreated": "2020-02-12 00:23:27.961",
      "dateStarted": "2020-02-12 00:23:55.451",
      "dateFinished": "2020-02-12 00:23:55.456",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nInizio con il creare una sequenza di coppie (stringa,valore). Una delle stringhe è un null, per crearla uso:\n\n`null.asInstanceOf[String]`",
      "user": "anonymous",
      "dateUpdated": "2020-06-30 20:43:21.982",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eInizio con il creare una sequenza di coppie (stringa,valore). Una delle stringhe è un null, per crearla uso:\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003enull.asInstanceOf[String]\u003c/code\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1593542484061_697610027",
      "id": "20200630-204124_633449042",
      "dateCreated": "2020-06-30 20:41:24.061",
      "dateStarted": "2020-06-30 20:43:21.982",
      "dateFinished": "2020-06-30 20:43:21.986",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val donuts \u003d Seq((\"plain donut\", 1.50), (null.asInstanceOf[String], 2.0), (\"glazed donut\", 2.50))",
      "user": "anonymous",
      "dateUpdated": "2020-06-30 20:44:32.182",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "donuts: Seq[(String, Double)] \u003d List((plain donut,1.5), (null,2.0), (glazed donut,2.5))\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581462022072_-1120964958",
      "id": "20200212-000022_851523032",
      "dateCreated": "2020-02-12 00:00:22.072",
      "dateStarted": "2020-06-30 20:44:32.194",
      "dateFinished": "2020-06-30 20:44:32.582",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\ntrasformo la sequenza generata in Dataframe",
      "user": "anonymous",
      "dateUpdated": "2020-06-30 20:44:22.093",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003etrasformo la sequenza generata in Dataframe\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1593542623793_960965168",
      "id": "20200630-204343_731135490",
      "dateCreated": "2020-06-30 20:43:43.793",
      "dateStarted": "2020-06-30 20:44:22.093",
      "dateFinished": "2020-06-30 20:44:22.097",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val dfWithNull \u003d spark\r\n  .createDataFrame(donuts)\r\n  .toDF(\"Donut Name\", \"Price\")",
      "user": "anonymous",
      "dateUpdated": "2020-06-30 20:44:34.851",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "dfWithNull: org.apache.spark.sql.DataFrame \u003d [Donut Name: string, Price: double]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581462064961_2001902493",
      "id": "20200212-000104_1280305592",
      "dateCreated": "2020-02-12 00:01:04.961",
      "dateStarted": "2020-06-30 20:44:34.864",
      "dateFinished": "2020-06-30 20:44:35.375",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "dfWithNull.show()",
      "user": "anonymous",
      "dateUpdated": "2020-06-30 20:45:11.854",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "java.net.SocketException: Connection reset\r\n\tat java.net.SocketInputStream.read(SocketInputStream.java:210)\r\n\tat java.net.SocketInputStream.read(SocketInputStream.java:141)\r\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\r\n\tat java.io.BufferedInputStream.read1(BufferedInputStream.java:286)\r\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:345)\r\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:127)\r\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\r\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\r\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\r\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\r\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\r\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)\r\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)\r\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\r\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\r\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\r\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\r\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)\r\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\r\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581462085270_1883955004",
      "id": "20200212-000125_1952630104",
      "dateCreated": "2020-02-12 00:01:25.270",
      "dateStarted": "2020-06-30 20:45:11.868",
      "dateFinished": "2020-06-30 20:59:00.577",
      "status": "ERROR",
      "errorMessage": "java.net.SocketException: Connection reset\r\n\tat java.net.SocketInputStream.read(SocketInputStream.java:210)\r\n\tat java.net.SocketInputStream.read(SocketInputStream.java:141)\r\n\tat java.io.BufferedInputStream.fill(BufferedInputStream.java:246)\r\n\tat java.io.BufferedInputStream.read1(BufferedInputStream.java:286)\r\n\tat java.io.BufferedInputStream.read(BufferedInputStream.java:345)\r\n\tat org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:127)\r\n\tat org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)\r\n\tat org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)\r\n\tat org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)\r\n\tat org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)\r\n\tat org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:69)\r\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.recv_interpret(RemoteInterpreterService.java:274)\r\n\tat org.apache.zeppelin.interpreter.thrift.RemoteInterpreterService$Client.interpret(RemoteInterpreterService.java:258)\r\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:233)\r\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter$4.call(RemoteInterpreter.java:229)\r\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterProcess.callRemoteFunction(RemoteInterpreterProcess.java:135)\r\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreter.interpret(RemoteInterpreter.java:228)\r\n\tat org.apache.zeppelin.notebook.Paragraph.jobRun(Paragraph.java:449)\r\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:188)\r\n\tat org.apache.zeppelin.scheduler.RemoteScheduler$JobRunner.run(RemoteScheduler.java:315)\r\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\r\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\r\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\r\n\tat java.lang.Thread.run(Thread.java:745)\r\n",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nCome trattare i valori nulli nei dati, opzione 1: eliminare la riga dove c\u0027è il null.\n\nUsando la funzione `drop`",
      "user": "anonymous",
      "dateUpdated": "2020-06-30 20:47:21.678",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eCome trattare i valori nulli nei dati, opzione 1: eliminare la riga dove c\u0026rsquo;è il null.\u003c/p\u003e\n\u003cp\u003eUsando la funzione \u003ccode\u003edrop\u003c/code\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1593542759651_-976841242",
      "id": "20200630-204559_1433675276",
      "dateCreated": "2020-06-30 20:45:59.651",
      "dateStarted": "2020-06-30 20:47:21.678",
      "dateFinished": "2020-06-30 20:47:21.682",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val dfWithoutNull \u003d dfWithNull.na.drop()\r\ndfWithoutNull.show()",
      "user": "anonymous",
      "dateUpdated": "2020-02-12 00:05:19.649",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+------------+-----+\n|  Donut Name|Price|\n+------------+-----+\n| plain donut|  1.5|\n|glazed donut|  2.5|\n+------------+-----+\n\r\ndfWithoutNull: org.apache.spark.sql.DataFrame \u003d [Donut Name: string, Price: double]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581462295219_1475503751",
      "id": "20200212-000455_389073392",
      "dateCreated": "2020-02-12 00:04:55.219",
      "dateStarted": "2020-02-12 00:05:19.663",
      "dateFinished": "2020-02-12 00:05:19.937",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "dfWithNull.na.fill(\"\").show",
      "user": "anonymous",
      "dateUpdated": "2020-02-12 00:06:05.279",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+------------+-----+\n|  Donut Name|Price|\n+------------+-----+\n| plain donut|  1.5|\n|            |  2.0|\n|glazed donut|  2.5|\n+------------+-----+\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581462319649_177458420",
      "id": "20200212-000519_822065032",
      "dateCreated": "2020-02-12 00:05:19.649",
      "dateStarted": "2020-02-12 00:06:05.294",
      "dateFinished": "2020-02-12 00:06:05.546",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "Come trattare i valori nulli nei dati, opzione 2: rimpiazzare il valore `null` con qualcos\u0027altro.",
      "user": "anonymous",
      "dateUpdated": "2020-06-30 20:48:41.361",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1593542847050_-1597501144",
      "id": "20200630-204727_189510621",
      "dateCreated": "2020-06-30 20:47:27.050",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "dfWithNull.na.replace(dfWithNull.columns, Map(\"null\" -\u003e \"unknown\")).show()",
      "user": "anonymous",
      "dateUpdated": "2020-02-12 00:22:42.741",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+------------+-----+\n|  Donut Name|Price|\n+------------+-----+\n| plain donut|  1.5|\n|        null|  2.0|\n|glazed donut|  2.5|\n+------------+-----+\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581462365279_1292948397",
      "id": "20200212-000605_711699361",
      "dateCreated": "2020-02-12 00:06:05.279",
      "dateStarted": "2020-02-12 00:22:42.755",
      "dateFinished": "2020-02-12 00:22:43.056",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val donuts \u003d Seq((\"plain donut\", 1.50), (\"vanilla donut\", 2.0), (\"glazed donut\", 2.50))\r\nval df \u003d spark.createDataFrame(donuts).toDF(\"Donut Name\", \"Price\")\r\n\r\nimport org.apache.spark.sql.functions._\r\nimport spark.sqlContext.implicits._\r\n\r\nval stockMinMax: (String \u003d\u003e Seq[Int]) \u003d (donutName: String) \u003d\u003e donutName match {\r\n    case \"plain donut\"    \u003d\u003e Seq(100, 500)\r\n    case \"vanilla donut\"  \u003d\u003e Seq(200, 400)\r\n    case \"glazed donut\"   \u003d\u003e Seq(300, 600)\r\n    case _                \u003d\u003e Seq(150, 150)\r\n  }\r\n\r\nval udfStockMinMax \u003d udf(stockMinMax)\r\n\r\nval df2 \u003d df.withColumn(\"Stock Min Max\", udfStockMinMax($\"Donut Name\"))\r\n\r\ndf2.show",
      "user": "anonymous",
      "dateUpdated": "2020-02-12 00:52:21.993",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------------+-----+-------------+\n|   Donut Name|Price|Stock Min Max|\n+-------------+-----+-------------+\n|  plain donut|  1.5|   [100, 500]|\n|vanilla donut|  2.0|   [200, 400]|\n| glazed donut|  2.5|   [300, 600]|\n+-------------+-----+-------------+\n\r\ndonuts: Seq[(String, Double)] \u003d List((plain donut,1.5), (vanilla donut,2.0), (glazed donut,2.5))\r\ndf: org.apache.spark.sql.DataFrame \u003d [Donut Name: string, Price: double]\r\nimport org.apache.spark.sql.functions._\r\nimport spark.sqlContext.implicits._\r\nstockMinMax: String \u003d\u003e Seq[Int] \u003d \u003cfunction1\u003e\r\nudfStockMinMax: org.apache.spark.sql.expressions.UserDefinedFunction \u003d UserDefinedFunction(\u003cfunction1\u003e,ArrayType(IntegerType,false),Some(List(StringType)))\r\ndf2: org.apache.spark.sql.DataFrame \u003d [Donut Name: string, Price: double ... 1 more field]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581462914276_1916877921",
      "id": "20200212-001514_670596174",
      "dateCreated": "2020-02-12 00:15:14.276",
      "dateStarted": "2020-02-12 00:52:22.008",
      "dateFinished": "2020-02-12 00:52:23.547",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val donuts \u003d Seq((\"plain donut\", 1.50), (\"vanilla donut\", 2.0), (\"glazed donut\", 2.50))\r\nval df \u003d spark.createDataFrame(donuts).toDF(\"Donut Name\", \"Price\")\r\n\r\nimport org.apache.spark.sql.functions._\r\n\r\nval df2 \u003d df\r\n    .withColumn(\"Tasty\", lit(true))\r\n    .withColumn(\"Correlation\", lit(1))\r\n    .withColumn(\"Stock Min Max\", typedLit(Seq(100, 500)))\r\n    \r\ndf2.show()",
      "user": "anonymous",
      "dateUpdated": "2020-02-12 00:56:16.302",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------------+-----+-----+-----------+-------------+\n|   Donut Name|Price|Tasty|Correlation|Stock Min Max|\n+-------------+-----+-----+-----------+-------------+\n|  plain donut|  1.5| true|          1|   [100, 500]|\n|vanilla donut|  2.0| true|          1|   [100, 500]|\n| glazed donut|  2.5| true|          1|   [100, 500]|\n+-------------+-----+-----+-----------+-------------+\n\r\ndonuts: Seq[(String, Double)] \u003d List((plain donut,1.5), (vanilla donut,2.0), (glazed donut,2.5))\r\ndf: org.apache.spark.sql.DataFrame \u003d [Donut Name: string, Price: double]\r\nimport org.apache.spark.sql.functions._\r\ndf2: org.apache.spark.sql.DataFrame \u003d [Donut Name: string, Price: double ... 3 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581465014854_-398999031",
      "id": "20200212-005014_438155032",
      "dateCreated": "2020-02-12 00:50:14.854",
      "dateStarted": "2020-02-12 00:56:16.319",
      "dateFinished": "2020-02-12 00:56:16.809",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val donuts \u003d Seq((\"plain donut\", 1.50), (\"vanilla donut\", 2.0), (\"glazed donut\", 2.50))\r\nval df \u003d spark.createDataFrame(donuts).toDF(\"Donut Name\", \"Price\")\r\ndf.show()\r\n\r\nval df2 \u003d df.withColumnRenamed(\"Donut Name\", \"Name\")\r\ndf2.show()",
      "user": "anonymous",
      "dateUpdated": "2020-02-12 00:57:12.627",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------------+-----+\n|   Donut Name|Price|\n+-------------+-----+\n|  plain donut|  1.5|\n|vanilla donut|  2.0|\n| glazed donut|  2.5|\n+-------------+-----+\n\r\n+-------------+-----+\n|         Name|Price|\n+-------------+-----+\n|  plain donut|  1.5|\n|vanilla donut|  2.0|\n| glazed donut|  2.5|\n+-------------+-----+\n\r\ndonuts: Seq[(String, Double)] \u003d List((plain donut,1.5), (vanilla donut,2.0), (glazed donut,2.5))\r\ndf: org.apache.spark.sql.DataFrame \u003d [Donut Name: string, Price: double]\r\ndf2: org.apache.spark.sql.DataFrame \u003d [Name: string, Price: double]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581465273758_-545446695",
      "id": "20200212-005433_396876124",
      "dateCreated": "2020-02-12 00:54:33.758",
      "dateStarted": "2020-02-12 00:57:12.644",
      "dateFinished": "2020-02-12 00:57:13.068",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// import sparkSession.sqlContext.implicits._\r\n\r\nval targets \u003d Seq((\"Plain Donut\", Array(1.50, 2.0)), (\"Vanilla Donut\", Array(2.0, 2.50)), (\"Strawberry Donut\", Array(2.50, 3.50)))\r\nval df \u003d spark \r\n    .createDataFrame(targets)\r\n    .toDF(\"Name\", \"Prices\")\r\n\r\ndf.show()\r\n",
      "user": "anonymous",
      "dateUpdated": "2020-02-12 01:01:28.888",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+----------------+----------+\n|            Name|    Prices|\n+----------------+----------+\n|     Plain Donut|[1.5, 2.0]|\n|   Vanilla Donut|[2.0, 2.5]|\n|Strawberry Donut|[2.5, 3.5]|\n+----------------+----------+\n\r\ntargets: Seq[(String, Array[Double])] \u003d List((Plain Donut,Array(1.5, 2.0)), (Vanilla Donut,Array(2.0, 2.5)), (Strawberry Donut,Array(2.5, 3.5)))\r\ndf: org.apache.spark.sql.DataFrame \u003d [Name: string, Prices: array\u003cdouble\u003e]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581465432627_-1879101766",
      "id": "20200212-005712_2144637116",
      "dateCreated": "2020-02-12 00:57:12.627",
      "dateStarted": "2020-02-12 01:01:04.144",
      "dateFinished": "2020-02-12 01:01:04.582",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.spark.sql.types.{StructField, StringType, ArrayType, MapType}\r\nimport spark.implicits._\r\n\r\nval arrayData \u003d Seq(\r\n    Row(\"James\",List(\"Java\",\"Scala\"),Map(\"hair\"-\u003e\"black\",\"eye\"-\u003e\"brown\")),\r\n    Row(\"Michael\",List(\"Spark\",\"Java\",null),Map(\"hair\"-\u003e\"brown\",\"eye\"-\u003enull)),\r\n    Row(\"Robert\",List(\"CSharp\",\"\"),Map(\"hair\"-\u003e\"red\",\"eye\"-\u003e\"\")),\r\n    Row(\"Washington\",null,null),\r\n    Row(\"Jefferson\",List(),Map())\r\n)\r\n\r\nval arraySchema \u003d new StructType()\r\n  .add(\"name\",StringType)\r\n  .add(\"knownLanguages\", ArrayType(StringType))\r\n  .add(\"properties\", MapType(StringType,StringType))\r\n\r\nval df \u003d spark.createDataFrame(spark.sparkContext.parallelize(arrayData),arraySchema)\r\ndf.printSchema()\r\ndf.show(false)",
      "user": "anonymous",
      "dateUpdated": "2020-02-12 01:38:02.127",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- name: string (nullable \u003d true)\n |-- knownLanguages: array (nullable \u003d true)\n |    |-- element: string (containsNull \u003d true)\n |-- properties: map (nullable \u003d true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull \u003d true)\n\r\n+----------+--------------+-----------------------------+\n|name      |knownLanguages|properties                   |\n+----------+--------------+-----------------------------+\n|James     |[Java, Scala] |[hair -\u003e black, eye -\u003e brown]|\n|Michael   |[Spark, Java,]|[hair -\u003e brown, eye -\u003e]      |\n|Robert    |[CSharp, ]    |[hair -\u003e red, eye -\u003e ]       |\n|Washington|null          |null                         |\n|Jefferson |[]            |[]                           |\n+----------+--------------+-----------------------------+\n\r\nimport org.apache.spark.sql.types.{StructField, StringType, ArrayType, MapType}\r\nimport spark.implicits._\r\narrayData: Seq[org.apache.spark.sql.Row] \u003d List([James,List(Java, Scala),Map(hair -\u003e black, eye -\u003e brown)], [Michael,List(Spark, Java, null),Map(hair -\u003e brown, eye -\u003e null)], [Robert,List(CSharp, ),Map(hair -\u003e red, eye -\u003e )], [Washington,null,null], [Jefferson,List(),Map()])\r\narraySchema: org.apache.spark.sql.types.StructType \u003d StructType(StructField(name,StringType,true), StructField(knownLanguages,ArrayType(StringType,true),true), StructField(properties,MapType(StringType,StringType,true),true))\r\ndf: org.apache.spark.sql.DataFrame \u003d [name: string, knownLanguages: array\u003cstring\u003e ... 1 more field]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581465511673_1688027564",
      "id": "20200212-005831_627933153",
      "dateCreated": "2020-02-12 00:58:31.673",
      "dateStarted": "2020-02-12 01:37:35.848",
      "dateFinished": "2020-02-12 01:37:37.346",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\ndf.select($\"name\",$\"knownLanguages\", explode($\"properties\")).select($\"name\", $\"key\", $\"value\",explode($\"knownLanguages\")).show(false)",
      "user": "anonymous",
      "dateUpdated": "2020-02-12 01:47:30.224",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------+----+-----+------+\n|name   |key |value|col   |\n+-------+----+-----+------+\n|James  |hair|black|Java  |\n|James  |hair|black|Scala |\n|James  |eye |brown|Java  |\n|James  |eye |brown|Scala |\n|Michael|hair|brown|Spark |\n|Michael|hair|brown|Java  |\n|Michael|hair|brown|null  |\n|Michael|eye |null |Spark |\n|Michael|eye |null |Java  |\n|Michael|eye |null |null  |\n|Robert |hair|red  |CSharp|\n|Robert |hair|red  |      |\n|Robert |eye |     |CSharp|\n|Robert |eye |     |      |\n+-------+----+-----+------+\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1581467755846_55562180",
      "id": "20200212-013555_1708314674",
      "dateCreated": "2020-02-12 01:35:55.846",
      "dateStarted": "2020-02-12 01:47:30.241",
      "dateFinished": "2020-02-12 01:47:30.706",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1581468229244_-127206692",
      "id": "20200212-014349_1925611362",
      "dateCreated": "2020-02-12 01:43:49.244",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "DataFrame basics 2",
  "id": "2EZYVA55A",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "sh:shared_process": [],
    "flink:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}