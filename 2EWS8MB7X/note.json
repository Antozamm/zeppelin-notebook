{
  "paragraphs": [
    {
      "text": "%md\n## Cosa sono le partizioni di Apache Spark?\n\n## È utile sapere che\nNel memorizzare i dati in partizioni vengono seguite queste regole:\n- Il numero di partizioni che vengono generate dipende dal numero di cores \n- Ogni nodo (executor) del cluster di Spark contiene una o più partizioni\n- Di default il numero di partizioni dovrebbe essere settato pari al numero di cores disponibili nel cluster, purtroppo non si può fissare direttamente il numero di partizioni. **NO NO NO non si può settare direttamente il numero delle partizioni** \n- Ogni partizione è interamente contenuta in un unico worker (o executor???)\n- Spark assegna un task per ogni partizione e di default ogni core può processare un task per volta\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.599",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eCosa sono le partizioni di Apache Spark?\u003c/h2\u003e\n\u003ch2\u003eÈ utile sapere che\u003c/h2\u003e\n\u003cp\u003eNel memorizzare i dati in partizioni vengono seguite queste regole:\u003cbr/\u003e- Il numero di partizioni che vengono generate dipende dal numero di cores\u003cbr/\u003e- Ogni nodo (executor) del cluster di Spark contiene una o più partizioni\u003cbr/\u003e- Di default il numero di partizioni dovrebbe essere settato pari al numero di cores disponibili nel cluster, purtroppo non si può fissare direttamente il numero di partizioni. \u003cstrong\u003eNO NO NO non si può settare direttamente il numero delle partizioni\u003c/strong\u003e\u003cbr/\u003e- Ogni partizione è interamente contenuta in un unico worker (o executor???)\u003cbr/\u003e- Spark assegna un task per ogni partizione e di default ogni core può processare un task per volta\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357593_-499010315",
      "id": "20191211-111114_1565692295",
      "dateCreated": "2020-01-06 13:05:57.593",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Esempio di partitioning\nUn esempio per capire l\u0027importanza del numero di partizioni.\n\nSupponiamo di avere un cluster con 4 core, e che i dati vengono suddivisi in 5 partizioni....\n\nUn numero di partizioni suggerito è pari al numero di cores del cluster. In questo modo ogni nodo (supponendo 1 nodo \u003d 1 core) riceve una partizione, e ho un numero di task pari al numero delle partizioni (core). L\u0027utilizzo del cluster è al 100%, ovvero o tutti i nodi sono impegnati. \n\n#FIGURA SOTTO\n\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.602",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eEsempio di partitioning\u003c/h3\u003e\n\u003cp\u003eUn esempio per capire l\u0026rsquo;importanza del numero di partizioni.\u003c/p\u003e\n\u003cp\u003eSupponiamo di avere un cluster con 4 core, e che i dati vengono suddivisi in 5 partizioni\u0026hellip;.\u003c/p\u003e\n\u003cp\u003eUn numero di partizioni suggerito è pari al numero di cores del cluster. In questo modo ogni nodo (supponendo 1 nodo \u003d 1 core) riceve una partizione, e ho un numero di task pari al numero delle partizioni (core). L\u0026rsquo;utilizzo del cluster è al 100%, ovvero o tutti i nodi sono impegnati. \u003c/p\u003e\n\u003cp\u003e#FIGURA SOTTO\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357601_1707074068",
      "id": "20200104-000359_1766048439",
      "dateCreated": "2020-01-06 13:05:57.601",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nPer vedere il numero di partizioni uso **getNumPartitions()** o **df.rdd.pastions.size()**.\nCarico un dataset di 7.55MB in un dataframe e controllo subito in quante partizioni è suddiviso il dataframe.\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.603",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003ePer vedere il numero di partizioni uso \u003cstrong\u003egetNumPartitions()\u003c/strong\u003e o \u003cstrong\u003edf.rdd.pastions.size()\u003c/strong\u003e.\u003cbr/\u003eCarico un dataset di 7.55MB in un dataframe e controllo subito in quante partizioni è suddiviso il dataframe.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357602_-1648171425",
      "id": "20191211-111725_28086690",
      "dateCreated": "2020-01-06 13:05:57.602",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val df \u003d spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"globalpowerplantdatabasev120/*.csv\")\nprintln(f\"Numero di partizioni del dataframe: ${df.rdd.partitions.size}\")",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.604",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Numero di partizioni del dataframe: 2\r\ndf: org.apache.spark.sql.DataFrame \u003d [country: string, country_long: string ... 22 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357603_1680744783",
      "id": "20191211-113930_2105717002",
      "dateCreated": "2020-01-06 13:05:57.603",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nPerché 2 partizioni soltanto?\nPerché Spark parte di default con due **executors** e un core per ogni executor. Per settare un numero di executors (cores) più alto si può usare **--num-executors** (e **--executor-cores**) al momento di lanciare il cluster.\n\nInvece di --num-executors si può settare la proprietà **spark.executor.instances**.\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.605",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003ePerché 2 partizioni soltanto?\u003cbr/\u003ePerché Spark parte di default con due \u003cstrong\u003eexecutors\u003c/strong\u003e e un core per ogni executor. Per settare un numero di executors (cores) più alto si può usare \u003cstrong\u003e\u0026ndash;num-executors\u003c/strong\u003e (e \u003cstrong\u003e\u0026ndash;executor-cores\u003c/strong\u003e) al momento di lanciare il cluster.\u003c/p\u003e\n\u003cp\u003eInvece di \u0026ndash;num-executors si può settare la proprietà \u003cstrong\u003espark.executor.instances\u003c/strong\u003e.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357604_-508021942",
      "id": "20200105-162802_1539673061",
      "dateCreated": "2020-01-06 13:05:57.604",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "spark.stop",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.605",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1578312357605_475743483",
      "id": "20200105-180314_546314396",
      "dateCreated": "2020-01-06 13:05:57.605",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.spark.sql.SparkSession\n\nval spark \u003d SparkSession.builder.master(\"local[4]\").config(\"spark.executor.instances\", 4)\n                                                   .config(\"spark.default.parallelism\", 4).getOrCreate()\n\n\nval numExecs \u003d spark.conf.get(\"spark.executor.instances\")\nprintln(f\"Numero di executors ${numExecs}\" )",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.606",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Numero di executors 4\r\nimport org.apache.spark.sql.SparkSession\r\nspark: org.apache.spark.sql.SparkSession \u003d org.apache.spark.sql.SparkSession@1093c6f8\r\nnumExecs: String \u003d 4\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357605_-1748600042",
      "id": "20200105-172541_599899694",
      "dateCreated": "2020-01-06 13:05:57.606",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nIl setting `sc.defaultMinPartitions` definisce il numero minimo di partizioni quando il dataframe è creato:\n\nQuesto parametro è definito internamente da Spark come il minimo tra defaultParallelism e 2, ciò significa che defaultMinPartitions non può essere più piccolo di 2. [vedi riferimento 1]\n\n**defaultParallelism** viene settato di default pari al numero di cores usato, **NO** che in Zeppelin di default è 1 **NO**. Posso settare questo in una nuova **Sparkession** con il metodo **master(\"local[x]\")**.\n\nSi noti che anche allocando un numero alto di executor, il numero minimo di partizioni create è 2.\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.607",
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eIl setting \u003ccode\u003esc.defaultMinPartitions\u003c/code\u003e definisce il numero minimo di partizioni quando il dataframe è creato:\u003c/p\u003e\n\u003cp\u003eQuesto parametro è definito internamente da Spark come il minimo tra defaultParallelism e 2, ciò significa che defaultMinPartitions non può essere più piccolo di 2. [vedi riferimento 1]\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003edefaultParallelism\u003c/strong\u003e viene settato di default pari al numero di cores usato, \u003cstrong\u003eNO\u003c/strong\u003e che in Zeppelin di default è 1 \u003cstrong\u003eNO\u003c/strong\u003e. Posso settare questo in una nuova \u003cstrong\u003eSparkession\u003c/strong\u003e con il metodo \u003cstrong\u003emaster(\u0026ldquo;local[x]\u0026rdquo;)\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eSi noti che anche allocando un numero alto di executor, il numero minimo di partizioni create è 2.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357606_1991811074",
      "id": "20191211-123655_801279717",
      "dateCreated": "2020-01-06 13:05:57.606",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "println(f\"sc.defaultParallelism: ${sc.defaultParallelism}\")\nprintln(f\"Numero minimo di partizioni: ${sc.defaultMinPartitions}\")",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.607",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "sc.defaultParallelism: 4\r\nNumero minimo di partizioni: 2\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357607_-1295070010",
      "id": "20191211-121001_507255553",
      "dateCreated": "2020-01-06 13:05:57.607",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nDiversi settaggi influiscono sul valore di **sc.defaultParallelism**:\n- se uso **master(\"local[x]\")** per usare x cores, defaultParallelism viene settato a x\n- si può definire nello SparkSession, per es.:\n```val spark \u003d SparkSession.builder().appName(\"TestPartitionNums\").master(\"local\").config(\"spark.default.parallelism\", 20).getOrCreate()```\n- si può settare nel file *spark-defaults.conf* con il settaggio: `spark.default.parallelism\u003d20`\n- in Apache Zeppelin si può anche settare nella GUI tra i parametri dell\u0027interprete Spark, creando un nuovo parametro con `spark.default.parallelism\u003d20`\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.608",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eDiversi settaggi influiscono sul valore di \u003cstrong\u003esc.defaultParallelism\u003c/strong\u003e:\u003cbr/\u003e- se uso \u003cstrong\u003emaster(\u0026ldquo;local[x]\u0026rdquo;)\u003c/strong\u003e per usare x cores, defaultParallelism viene settato a x\u003cbr/\u003e- si può definire nello SparkSession, per es.:\u003cbr/\u003e\u003ccode\u003eval spark \u003d SparkSession.builder().appName(\u0026quot;TestPartitionNums\u0026quot;).master(\u0026quot;local\u0026quot;).config(\u0026quot;spark.default.parallelism\u0026quot;, 20).getOrCreate()\u003c/code\u003e\u003cbr/\u003e- si può settare nel file \u003cem\u003espark-defaults.conf\u003c/em\u003e con il settaggio: \u003ccode\u003espark.default.parallelism\u003d20\u003c/code\u003e\u003cbr/\u003e- in Apache Zeppelin si può anche settare nella GUI tra i parametri dell\u0026rsquo;interprete Spark, creando un nuovo parametro con \u003ccode\u003espark.default.parallelism\u003d20\u003c/code\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357608_1386933764",
      "id": "20191211-124201_1141603656",
      "dateCreated": "2020-01-06 13:05:57.608",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "spark.stop",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.609",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1578312357608_-1056130282",
      "id": "20191211-120018_821827504",
      "dateCreated": "2020-01-06 13:05:57.608",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.spark.sql.SparkSession\nval spark \u003d SparkSession.builder.master(\"local[*]\").getOrCreate()\nval sc \u003d spark.sparkContext\n\nval df \u003d spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"globalpowerplantdatabasev120/*.csv\")\ndf.rdd.getNumPartitions",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.609",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.sql.SparkSession\r\nspark: org.apache.spark.sql.SparkSession \u003d org.apache.spark.sql.SparkSession@78b6cc3c\r\nsc: org.apache.spark.SparkContext \u003d org.apache.spark.SparkContext@544cbb2\r\ndf: org.apache.spark.sql.DataFrame \u003d [country: string, country_long: string ... 22 more fields]\r\nres4: Int \u003d 2\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357609_-159245880",
      "id": "20191211-114655_2070483524",
      "dateCreated": "2020-01-06 13:05:57.609",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "println(f\"sc.defaultParallelism: ${sc.defaultParallelism}\")\nprintln(f\"Numero minimo di partizioni: ${sc.defaultMinPartitions}\")",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.610",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "sc.defaultParallelism: 4\r\nNumero minimo di partizioni: 2\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357610_-995168604",
      "id": "20191211-120033_1744201914",
      "dateCreated": "2020-01-06 13:05:57.610",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nIl parametro fondamentale per capire quante partizioni vengono generate è\n`spark.sql.files.maxPartitionBytes`\nCome si evince dal nome, questo parametro definisce il massimo spazio su disco per ogni partizione.\nSetto questo parametro a 1M (il default è 128MB), con un file dati da 7.55MB, implica che vengono create **ceil(7.55M/1M) \u003d 8** partizioni.\nSi noti che viene anche rispettato il parametro **defaultMinPartitions** (\u003d 2).\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.611",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eIl parametro fondamentale per capire quante partizioni vengono generate è\u003cbr/\u003e\u003ccode\u003espark.sql.files.maxPartitionBytes\u003c/code\u003e\u003cbr/\u003eCome si evince dal nome, questo parametro definisce il massimo spazio su disco per ogni partizione.\u003cbr/\u003eSetto questo parametro a 1M (il default è 128MB), con un file dati da 7.55MB, implica che vengono create \u003cstrong\u003eceil(7.55M/1M) \u003d 8\u003c/strong\u003e partizioni.\u003cbr/\u003eSi noti che viene anche rispettato il parametro \u003cstrong\u003edefaultMinPartitions\u003c/strong\u003e (\u003d 2).\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357610_-359966022",
      "id": "20191211-120627_1269901082",
      "dateCreated": "2020-01-06 13:05:57.610",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"1000000\")\nval df \u003d spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"globalpowerplantdatabasev120/*.csv\")\n\nprintln(f\"sc.defaultParallelism: ${sc.defaultParallelism}\")\nprintln(f\"Numero minimo di partizioni: ${sc.defaultMinPartitions}\")\nprintln(f\"Numero effettivo di partizioni: ${df.rdd.getNumPartitions}\")",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.611",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "sc.defaultParallelism: 4\r\nNumero minimo di partizioni: 2\r\nNumero di partizioni: 8\r\ndf: org.apache.spark.sql.DataFrame \u003d [country: string, country_long: string ... 22 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357611_545401672",
      "id": "20191211-121123_739577557",
      "dateCreated": "2020-01-06 13:05:57.611",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.612",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1578312357612_359127154",
      "id": "20200105-033821_837933988",
      "dateCreated": "2020-01-06 13:05:57.612",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "spark.stop\nsc.stop",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.613",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1578312357612_793855585",
      "id": "20191211-123415_1070340983",
      "dateCreated": "2020-01-06 13:05:57.612",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \nSi noti che con le impostazioni di default usate sotto ho 4 cores e 2 partizioni. Nel momento in cui verranno fatti i primi calcoli sui dati, verrà assegnato un task per ogni partizione, ogni task girerà su un core. Avremo pertanto che solo 2 cores saranno utilizzati, con grosso spreco di risorse (2 cores inutilizzati) e un maggior tempo di elaborazione.\n\nRicordiamo: **N partizioni \u003d\u003e N task \u003d\u003e N cores utilizzati** \n\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.613",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eSi noti che con le impostazioni di default usate sotto ho 4 cores e 2 partizioni. Nel momento in cui verranno fatti i primi calcoli sui dati, verrà assegnato un task per ogni partizione, ogni task girerà su un core. Avremo pertanto che solo 2 cores saranno utilizzati, con grosso spreco di risorse (2 cores inutilizzati) e un maggior tempo di elaborazione.\u003c/p\u003e\n\u003cp\u003eRicordiamo: \u003cstrong\u003eN partizioni \u003d\u0026gt; N task \u003d\u0026gt; N cores utilizzati\u003c/strong\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357613_464379712",
      "id": "20200105-034000_1029880386",
      "dateCreated": "2020-01-06 13:05:57.613",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.spark.SparkConf\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.SparkSession\n\nval conf \u003d new SparkConf().setMaster(\"local[*]\").setAppName(\"NewApp\")\nval sc \u003d new SparkContext(conf)\nval spark \u003d SparkSession.builder.master(\"local[*]\").getOrCreate()\n\nval df \u003d spark.read.option(\"inferSchema\", \"true\").option(\"header\", \"true\").csv(\"globalpowerplantdatabasev120/*.csv\")\n\nprintln(f\"Numero di Executors: ${sc.defaultParallelism}\")\nprintln(f\"Numero minimo di partizioni: ${sc.defaultMinPartitions}\")\nprintln(f\"Numero di partizioni: ${df.rdd.getNumPartitions}\")",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.614",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Numero di Executors: 4\r\nNumero minimo di partizioni: 2\r\nNumero di partizioni: 2\r\nimport org.apache.spark.SparkConf\r\nimport org.apache.spark.SparkContext\r\nimport org.apache.spark.sql.SparkSession\r\nconf: org.apache.spark.SparkConf \u003d org.apache.spark.SparkConf@2a68dd0b\r\nsc: org.apache.spark.SparkContext \u003d org.apache.spark.SparkContext@6fc8f8ab\r\nspark: org.apache.spark.sql.SparkSession \u003d org.apache.spark.sql.SparkSession@3e7cb231\r\ndf: org.apache.spark.sql.DataFrame \u003d [country: string, country_long: string ... 22 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357614_-1568352958",
      "id": "20191211-122113_379911460",
      "dateCreated": "2020-01-06 13:05:57.614",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nPer uno sfruttamento ottimale del cluster dovremmo settare **spark.sql.files.maxPartitionBytes** in modo tale da avere un numero di partizioni pari a 4: se il file è di 7.55MB questo significa spark.sql.files.maxPartitionBytes \u003d 2M",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.615",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003ePer uno sfruttamento ottimale del cluster dovremmo settare \u003cstrong\u003espark.sql.files.maxPartitionBytes\u003c/strong\u003e in modo tale da avere un numero di partizioni pari a 4: se il file è di 7.55MB questo significa spark.sql.files.maxPartitionBytes \u003d 2M\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357614_121312496",
      "id": "20200105-034745_1183650256",
      "dateCreated": "2020-01-06 13:05:57.614",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nAbbiamo visto come cambia il numero delle partizioni quando una struttura di **dati in ingresso viene generata**.\n\nMa il numero delle partizioni non è fisso dall\u0027inizio alla fine della applicazione, infatti esso cambia se triggeriamo uno shuffle dei dati, ovvero se utilizziamo una trasformazione che implica uno shuffle (**wide transformation**). Per esempio ...\n\nCome si può vedere sotto il numero delle partizioni dopo le operazioni **groupBy()** e **max()** è diventato 200. Perchè?\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.616",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eAbbiamo visto come cambia il numero delle partizioni quando una struttura di \u003cstrong\u003edati in ingresso viene generata\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eMa il numero delle partizioni non è fisso dall\u0026rsquo;inizio alla fine della applicazione, infatti esso cambia se triggeriamo uno shuffle dei dati, ovvero se utilizziamo una trasformazione che implica uno shuffle (**wide transformation**). Per esempio \u0026hellip;\u003c/p\u003e\n\u003cp\u003eCome si può vedere sotto il numero delle partizioni dopo le operazioni \u003cstrong\u003egroupBy()\u003c/strong\u003e e \u003cstrong\u003emax()\u003c/strong\u003e è diventato 200. Perchè?\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357615_-1322433089",
      "id": "20200105-032003_1472496855",
      "dateCreated": "2020-01-06 13:05:57.615",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val newdf \u003d df.groupBy(\"country\").max(\"estimated_generation_gwh\")\nnewdf.rdd.getNumPartitions",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.616",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "newdf: org.apache.spark.sql.DataFrame \u003d [country: string, max(estimated_generation_gwh): double]\r\nres31: Int \u003d 200\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357616_-1206390660",
      "id": "20191211-145314_1450041834",
      "dateCreated": "2020-01-06 13:05:57.616",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.617",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1578312357616_-61639383",
      "id": "20200104-112553_25467890",
      "dateCreated": "2020-01-06 13:05:57.616",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nCome si vede sopra dopo le operazioni **groupBy()** e **aggregate** ho 200 partizioni, questo perchè il parametro spark.sql.shuffle.partitions è settato a 200. Ricordiamo che quest\u0027ultimo fissa il numero di partizioni create da un\u0027operazione che1 implica uno shuffle, come ad esempio **groupBy**.\n\nNella UI di Spark si può vedere come è cambiato il numero di task e conseguentemente di partizioni, da 1 a 200.\n![spark ui stages](https://www.1week4.com/wp-content/uploads/2019/12/spark-ui-stages1.jpg)",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.617",
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eCome si vede sopra dopo le operazioni \u003cstrong\u003egroupBy()\u003c/strong\u003e e \u003cstrong\u003eaggregate\u003c/strong\u003e ho 200 partizioni, questo perchè il parametro spark.sql.shuffle.partitions è settato a 200. Ricordiamo che quest\u0026rsquo;ultimo fissa il numero di partizioni create da un\u0026rsquo;operazione che1 implica uno shuffle, come ad esempio \u003cstrong\u003egroupBy\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eNella UI di Spark si può vedere come è cambiato il numero di task e conseguentemente di partizioni, da 1 a 200.\u003cbr/\u003e\u003cimg src\u003d\"https://www.1week4.com/wp-content/uploads/2019/12/spark-ui-stages1.jpg\" alt\u003d\"spark ui stages\" /\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357617_-217485626",
      "id": "20191211-155312_1902930156",
      "dateCreated": "2020-01-06 13:05:57.617",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## spark.executor.cores\n## spark.task.cpus",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.618",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1578312357618_907903238",
      "id": "20200104-013042_456316799",
      "dateCreated": "2020-01-06 13:05:57.618",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "//   Default min number of partitions for Hadoop RDDs when not given by user\r\n//   Notice that we use math.min so the \"defaultMinPartitions\" cannot be higher than 2.\r\n//   The reasons for this are discussed in https://github.com/mesos/spark/pull/718\r\n//   \r\n//  def defaultMinPartitions: Int \u003d math.min(defaultParallelism, 2)",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.619",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1578312357618_-284479766",
      "id": "20191211-125437_1840307153",
      "dateCreated": "2020-01-06 13:05:57.618",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n| settaggio | default | spiegazione |\n|---------|---------|-------------|\n|spark.driver.cores|1|setta il numero di cores usati dal driver|\n|spark.executor.cores|1 in modo YARN. Tutti i cores disponibili in modo Spark standalone e con Mesos | il numero di cores per ogni executor in fase di lancio del nodo|\n|spark.task.cpu | 1 | numero di task da allocare per ciascun core|\n|spark.cores.max| non settato | il massimo numero di cores del cluster (totale, non per ogni executor) da assegnare **all\u0027applicazione**. Solo per Spark standalone e Mesos \"coarse-grained\" |\n|spark.deploy.defaultCores| illimitato | numero default di cores del cluster da assegnare in Spark standalone se non è assegnato spark.cores.max. Si può usare per limitare il numero di cores da assegnare a diversi user di un cluster condiviso|\n|spark.default.parallelism \u003cbr\u003esc.defaultParallelism| numero di cores??? | numero di default delle partizioni generate da operazioni quali *join* e *reduceByKey* e *parallelize*|\n\n\n#### Esempio\nSupponendo di essere in **cluster mode**, settando: \n- spark.cores.max \u003d 5\n- spark.driver.cores \u003d 1\n- spark.executor.cores \u003d 2\n\navrò un numero di executors pari a\n\n#executors \u003d (spark.cores.max - spark.driver.cores)/spark.executor.cores \u003d 2\n\n\n",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.619",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n    \u003ctr\u003e\n      \u003cth\u003esettaggio \u003c/th\u003e\n      \u003cth\u003edefault \u003c/th\u003e\n      \u003cth\u003espiegazione \u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003ctd\u003espark.driver.cores\u003c/td\u003e\n      \u003ctd\u003e1\u003c/td\u003e\n      \u003ctd\u003esetta il numero di cores usati dal driver\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003espark.executor.cores\u003c/td\u003e\n      \u003ctd\u003e1 in modo YARN. Tutti i cores disponibili in modo Spark standalone e con Mesos \u003c/td\u003e\n      \u003ctd\u003eil numero di cores per ogni executor in fase di lancio del nodo\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003espark.task.cpu \u003c/td\u003e\n      \u003ctd\u003e1 \u003c/td\u003e\n      \u003ctd\u003enumero di task da allocare per ciascun core\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003espark.cores.max\u003c/td\u003e\n      \u003ctd\u003enon settato \u003c/td\u003e\n      \u003ctd\u003eil massimo numero di cores del cluster (totale, non per ogni executor) da assegnare \u003cstrong\u003eall\u0026rsquo;applicazione\u003c/strong\u003e. Solo per Spark standalone e Mesos \u0026ldquo;coarse-grained\u0026rdquo; \u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003espark.deploy.defaultCores\u003c/td\u003e\n      \u003ctd\u003eillimitato \u003c/td\u003e\n      \u003ctd\u003enumero default di cores del cluster da assegnare in Spark standalone se non è assegnato spark.cores.max. Si può usare per limitare il numero di cores da assegnare a diversi user di un cluster condiviso\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003ctd\u003espark.default.parallelism \u003cbr\u003esc.defaultParallelism\u003c/td\u003e\n      \u003ctd\u003enumero di cores??? \u003c/td\u003e\n      \u003ctd\u003enumero di default delle partizioni generate da operazioni quali \u003cem\u003ejoin\u003c/em\u003e e \u003cem\u003ereduceByKey\u003c/em\u003e e \u003cem\u003eparallelize\u003c/em\u003e\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch4\u003eEsempio\u003c/h4\u003e\n\u003cp\u003eSupponendo di essere in \u003cstrong\u003ecluster mode\u003c/strong\u003e, settando:\u003cbr/\u003e- spark.cores.max \u003d 5\u003cbr/\u003e- spark.driver.cores \u003d 1\u003cbr/\u003e- spark.executor.cores \u003d 2\u003c/p\u003e\n\u003cp\u003eavrò un numero di executors pari a\u003c/p\u003e\n\u003cp\u003e#executors \u003d (spark.cores.max - spark.driver.cores)/spark.executor.cores \u003d 2\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357619_-358237315",
      "id": "20200104-234415_320317775",
      "dateCreated": "2020-01-06 13:05:57.619",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nRiferimenti\n1. [Spark Github](https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SparkContext.scala#L799)\n2. https://www.dezyre.com/article/how-data-partitioning-in-spark-helps-achieve-more-parallelism/297",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.620",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eRiferimenti\u003cbr/\u003e1. \u003ca href\u003d\"https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SparkContext.scala#L799\"\u003eSpark Github\u003c/a\u003e\u003cbr/\u003e2. \u003ca href\u003d\"https://www.dezyre.com/article/how-data-partitioning-in-spark-helps-achieve-more-parallelism/297\"\u003ehttps://www.dezyre.com/article/how-data-partitioning-in-spark-helps-achieve-more-parallelism/297\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357620_-171254161",
      "id": "20191211-130043_314232691",
      "dateCreated": "2020-01-06 13:05:57.620",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "spark.conf.getAll.foreach(println)",
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.621",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "(spark.driver.host,LAPTOP-CD5FRQQG)\r\n(spark.driver.port,7778)\r\n(spark.jars,file:///C:/zeppelin-0.8.2-bin-all-local/interpreter/spark/spark-interpreter-0.8.2.jar,file:/C:/zeppelin-0.8.2-bin-all-local/interpreter/spark/spark-interpreter-0.8.2.jar)\r\n(spark.app.name,Zeppelin)\r\n(spark.executor.instances,4)\r\n(spark.executor.id,driver)\r\n(spark.driver.extraJavaOptions, -Dfile.encoding\u003dUTF-8 -Dzeppelin.log.file\u003d\u0027C:\\zeppelin-0.8.2-bin-all-local\\logs\\zeppelin-interpreter-spark-Anto-LAPTOP-CD5FRQQG.log\u0027)\r\n(spark.submit.deployMode,client)\r\n(spark.master,local[4])\r\n(spark.repl.local.jars,file:///C:/zeppelin-0.8.2-bin-all-local/interpreter/spark/spark-interpreter-0.8.2.jar)\r\n(spark.app.id,local-1578244297950)\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1578312357620_-545636144",
      "id": "20191211-130103_1686291439",
      "dateCreated": "2020-01-06 13:05:57.620",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "dateUpdated": "2020-01-06 13:05:57.621",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1578312357621_1689958298",
      "id": "20200104-112837_2034204350",
      "dateCreated": "2020-01-06 13:05:57.621",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "~Trash/Partitions",
  "id": "2EWS8MB7X",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}