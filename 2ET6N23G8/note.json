{
  "paragraphs": [
    {
      "text": "%md\n## Configurazione del cluster\nImportiamo la SparkSesssion, il punto di accesso al cluster per tutte le attività di Spark.",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:12:58.259",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eConfigurazione del cluster\u003c/h2\u003e\n\u003cp\u003eImportiamo la SparkSesssion, il punto di accesso al cluster per tutte le attività di Spark.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574674191825_-1307089363",
      "id": "20191125-102951_96032273",
      "dateCreated": "2019-11-25 10:29:51.826",
      "dateStarted": "2019-11-27 14:12:58.321",
      "dateFinished": "2019-11-27 14:13:04.021",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.spark.sql.SparkSession",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:04.045",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.sql.SparkSession\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574674146818_2070972959",
      "id": "20191125-102906_1597767286",
      "dateCreated": "2019-11-25 10:29:06.818",
      "dateStarted": "2019-11-27 14:13:04.125",
      "dateFinished": "2019-11-27 14:13:15.832",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nDefinisco e configuro una SparkSession, ho bisogno del metodo **builder**, assegno un nome alla applicazione Spark usando **appName**, definisco che il cluster funziona in modo locale. Infine uso getOrCreate, cioè crea una nuova SparkSession o usa una già esistente.  ",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:15.887",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eDefinisco e configuro una SparkSession, ho bisogno del metodo \u003cstrong\u003ebuilder\u003c/strong\u003e, assegno un nome alla applicazione Spark usando \u003cstrong\u003eappName\u003c/strong\u003e, definisco che il cluster funziona in modo locale. Infine uso getOrCreate, cioè crea una nuova SparkSession o usa una già esistente.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574674841771_1876021451",
      "id": "20191125-104041_1369871670",
      "dateCreated": "2019-11-25 10:40:41.772",
      "dateStarted": "2019-11-27 14:13:15.956",
      "dateFinished": "2019-11-27 14:13:15.970",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val spark \u003d SparkSession.builder.appName(\"MyApp1\").master(\"local\").getOrCreate",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:16.055",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "spark: org.apache.spark.sql.SparkSession \u003d org.apache.spark.sql.SparkSession@22161fb9\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574674187077_273060964",
      "id": "20191125-102947_64480312",
      "dateCreated": "2019-11-25 10:29:47.077",
      "dateStarted": "2019-11-27 14:13:16.139",
      "dateFinished": "2019-11-27 14:13:17.057",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nSe voglio vedere tutte le proprietà di configurazione posso usare **spark.conf.getAll** che restituisce un **map** di coppie key,value, ciscuna coppia contenente una proprietà della configurazione del cluster.",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:17.143",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eSe voglio vedere tutte le proprietà di configurazione posso usare \u003cstrong\u003espark.conf.getAll\u003c/strong\u003e che restituisce un \u003cstrong\u003emap\u003c/strong\u003e di coppie key,value, ciscuna coppia contenente una proprietà della configurazione del cluster.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574675047297_-619468556",
      "id": "20191125-104407_1554911329",
      "dateCreated": "2019-11-25 10:44:07.297",
      "dateStarted": "2019-11-27 14:13:17.194",
      "dateFinished": "2019-11-27 14:13:17.204",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "spark.conf.getAll",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:17.294",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "res1: Map[String,String] \u003d Map(zeppelin.pyspark.python -\u003e python, spark.driver.host -\u003e 10.0.75.1, zeppelin.dep.localrepo -\u003e local-repo, zeppelin.spark.sql.stacktrace -\u003e false, spark.driver.port -\u003e 53386, master -\u003e local[*], spark.repl.class.uri -\u003e spark://10.0.75.1:53386/classes, zeppelin.spark.useHiveContext -\u003e true, spark.repl.class.outputDir -\u003e C:\\Users\\home\\AppData\\Local\\Temp\\spark8113731899773902274, zeppelin.spark.sql.interpolation -\u003e false, zeppelin.spark.importImplicit -\u003e true, zeppelin.interpreter.output.limit -\u003e 102400, spark.app.name -\u003e MyApp1, zeppelin.R.cmd -\u003e R, zeppelin.spark.maxResult -\u003e 1000, zeppelin.pyspark.useIPython -\u003e true, zeppelin.spark.concurrentSQL -\u003e false, zeppelin.spark.enableSupportedVersionCheck -\u003e true, zeppelin.spark.printREPLOutput -\u003e true, zeppelin.dep..."
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574680426740_-576525551",
      "id": "20191125-121346_1893066719",
      "dateCreated": "2019-11-25 12:13:46.740",
      "dateStarted": "2019-11-27 14:13:17.349",
      "dateFinished": "2019-11-27 14:13:17.922",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nPer visualizzare meglio i field del **map**, posso usare la funzione **foreach** con argomento la funzione **println**.\nDa ricordare che in **Scala** esistono le funzioni di ordine superiore, cioè funzioni che accettano come argomento un altra funzione.",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:17.950",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003ePer visualizzare meglio i field del \u003cstrong\u003emap\u003c/strong\u003e, posso usare la funzione \u003cstrong\u003eforeach\u003c/strong\u003e con argomento la funzione \u003cstrong\u003eprintln\u003c/strong\u003e.\u003cbr/\u003eDa ricordare che in \u003cstrong\u003eScala\u003c/strong\u003e esistono le funzioni di ordine superiore, cioè funzioni che accettano come argomento un altra funzione.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574680458046_-1385260751",
      "id": "20191125-121418_1278282582",
      "dateCreated": "2019-11-25 12:14:18.046",
      "dateStarted": "2019-11-27 14:13:18.034",
      "dateFinished": "2019-11-27 14:13:18.043",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "spark.conf.getAll.foreach(println)",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:18.134",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "(zeppelin.pyspark.python,python)\r\n(spark.driver.host,10.0.75.1)\r\n(zeppelin.dep.localrepo,local-repo)\r\n(zeppelin.spark.sql.stacktrace,false)\r\n(spark.driver.port,53386)\r\n(master,local[*])\r\n(spark.repl.class.uri,spark://10.0.75.1:53386/classes)\r\n(zeppelin.spark.useHiveContext,true)\r\n(spark.repl.class.outputDir,C:\\Users\\home\\AppData\\Local\\Temp\\spark8113731899773902274)\r\n(zeppelin.spark.sql.interpolation,false)\r\n(zeppelin.spark.importImplicit,true)\r\n(zeppelin.interpreter.output.limit,102400)\r\n(spark.app.name,MyApp1)\r\n(zeppelin.R.cmd,R)\r\n(zeppelin.spark.maxResult,1000)\r\n(zeppelin.pyspark.useIPython,true)\r\n(zeppelin.spark.concurrentSQL,false)\r\n(zeppelin.spark.enableSupportedVersionCheck,true)\r\n(zeppelin.spark.printREPLOutput,true)\r\n(zeppelin.dep.additionalRemoteRepository,spark-packages,http://dl.bintray.com/spark-packages/maven,false;)\r\n(spark.executor.id,driver)\r\n(zeppelin.spark.useNew,true)\r\n(spark.useHiveContext,true)\r\n(spark.master,local)\r\n(zeppelin.R.image.width,100%)\r\n(zeppelin.spark.ui.hidden,false)\r\n(zeppelin.interpreter.localRepo,C:\\zeppelin-0.8.2-bin-all/local-repo/spark)\r\n(zeppelin.R.render.options,out.format \u003d \u0027html\u0027, comment \u003d NA, echo \u003d FALSE, results \u003d \u0027asis\u0027, message \u003d F, warning \u003d F, fig.retina \u003d 2)\r\n(zeppelin.interpreter.max.poolsize,10)\r\n(spark.app.id,local-1574860392257)\r\n(zeppelin.R.knitr,true)\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574674480175_1740071417",
      "id": "20191125-103440_299176729",
      "dateCreated": "2019-11-25 10:34:40.175",
      "dateStarted": "2019-11-27 14:13:18.175",
      "dateFinished": "2019-11-27 14:13:18.706",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Importazione dei dati\n\nI dati sono in un file csv. Questi possono essere importati comodamente in un **DataFrame** o in un **RDD**, dipendentemente a quale struttura voglio usare.\n\nPoichè sono dati numerici in formato tabellare è sicuramente più comodo usare i DataFrame\nPrima importo il package Dataframe, e poi importiamo il file csv in un Dataframe nuovo di zecca.\n\nIl DataFrame di Spark è molto simile al DataFrame di Numpy per Python. Si tratta di un insieme di dati in formato tabella con le colonne aventi dei nomi per identificarle .\nCon l\u0027opzione **(\"Header\",\"true\")** comunico che la prima riga ha la funzione di *Header* per cui le colonne del DataFrame verranno nominate usando l\u0027header.\nIn alternativa spark avrebbe assegnato i nomi generici _c0, _c1, _c2... e la prima riga sarebbe finita tra i dati.",
      "user": "anonymous",
      "dateUpdated": "2019-11-28 12:42:02.858",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eImportazione dei dati\u003c/h2\u003e\n\u003cp\u003eI dati sono in un file csv. Questi possono essere importati comodamente in un \u003cstrong\u003eDataFrame\u003c/strong\u003e o in un \u003cstrong\u003eRDD\u003c/strong\u003e, dipendentemente a quale struttura voglio usare.\u003c/p\u003e\n\u003cp\u003ePoichè sono dati numerici in formato tabellare è sicuramente più comodo usare i DataFrame\u003cbr/\u003ePrima importo il package Dataframe, e poi importiamo il file csv in un Dataframe nuovo di zecca.\u003c/p\u003e\n\u003cp\u003eIl DataFrame di Spark è molto simile al DataFrame di Numpy per Python. Si tratta di un insieme di dati in formato tabella con le colonne aventi dei nomi per identificarle .\u003cbr/\u003eCon l\u0026rsquo;opzione \u003cstrong\u003e(\u0026ldquo;Header\u0026rdquo;,\u0026ldquo;true\u0026rdquo;)\u003c/strong\u003e comunico che la prima riga ha la funzione di \u003cem\u003eHeader\u003c/em\u003e per cui le colonne del DataFrame verranno nominate usando l\u0026rsquo;header.\u003cbr/\u003eIn alternativa spark avrebbe assegnato i nomi generici _c0, _c1, _c2\u0026hellip; e la prima riga sarebbe finita tra i dati.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574674480043_-832882968",
      "id": "20191125-103440_1520293990",
      "dateCreated": "2019-11-25 10:34:40.043",
      "dateStarted": "2019-11-28 12:42:02.866",
      "dateFinished": "2019-11-28 12:42:08.882",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.spark.sql.DataFrame\n\nval df \u003d spark.read.option(\"Header\",\"true\").csv(\"exampl1.csv\")",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:18.939",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.sql.DataFrame\r\ndf: org.apache.spark.sql.DataFrame \u003d [eta: string, amici: string]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574683388711_-629324192",
      "id": "20191125-130308_110147485",
      "dateCreated": "2019-11-25 13:03:08.711",
      "dateStarted": "2019-11-27 14:13:18.983",
      "dateFinished": "2019-11-27 14:13:20.876",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nCome possiamo vedere sopra Spark mi dice che l\u0027oggetto DataFrame ha 2 colonne di nome rispettivamente *eta* e *amici*, e che tutti e due i campi contengono stringhe.\nPoiché in realtà i campi del file sono valori interi, posso fare in modo che nell\u0027importazione i valori siano interpretati correttamente come valori numerici interi.\nPer fare ciò uso l\u0027opzione (\"inferSchema\",\"true\") in cui comunico al sistema di inferire il tipo dei valori nelle colonne.",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:20.894",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eCome possiamo vedere sopra Spark mi dice che l\u0026rsquo;oggetto DataFrame ha 2 colonne di nome rispettivamente \u003cem\u003eeta\u003c/em\u003e e \u003cem\u003eamici\u003c/em\u003e, e che tutti e due i campi contengono stringhe.\u003cbr/\u003ePoiché in realtà i campi del file sono valori interi, posso fare in modo che nell\u0026rsquo;importazione i valori siano interpretati correttamente come valori numerici interi.\u003cbr/\u003ePer fare ciò uso l\u0026rsquo;opzione (\u0026ldquo;inferSchema\u0026rdquo;,\u0026ldquo;true\u0026rdquo;) in cui comunico al sistema di inferire il tipo dei valori nelle colonne.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574683416989_41940561",
      "id": "20191125-130336_1924810457",
      "dateCreated": "2019-11-25 13:03:36.989",
      "dateStarted": "2019-11-27 14:13:20.953",
      "dateFinished": "2019-11-27 14:13:20.965",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val df \u003d spark.read.option(\"Header\",\"true\").option(\"inferSchema\",\"true\").csv(\"exampl1.csv\")",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:21.052",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "df: org.apache.spark.sql.DataFrame \u003d [eta: int, amici: int]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574684257996_1456929141",
      "id": "20191125-131737_1111301496",
      "dateCreated": "2019-11-25 13:17:37.996",
      "dateStarted": "2019-11-27 14:13:21.093",
      "dateFinished": "2019-11-27 14:13:21.558",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nI nomi delle colonne li conosco, ma se voglio verificare posso usare il metodo **columns**",
      "user": "anonymous",
      "dateUpdated": "2019-11-28 12:44:01.581",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eI nomi delle colonne li conosco, ma se voglio verificare posso usare il metodo \u003cstrong\u003ecolumns\u003c/strong\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574683918819_432639864",
      "id": "20191125-131158_1574211598",
      "dateCreated": "2019-11-25 13:11:58.819",
      "dateStarted": "2019-11-28 12:44:01.581",
      "dateFinished": "2019-11-28 12:44:01.593",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.columns",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:21.741",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "res3: Array[String] \u003d Array(eta, amici)\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574683974350_-2047343485",
      "id": "20191125-131254_1091874570",
      "dateCreated": "2019-11-25 13:12:54.350",
      "dateStarted": "2019-11-27 14:13:21.783",
      "dateFinished": "2019-11-27 14:13:22.040",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nAdesso che i dati sono correttamente interpretati come numerici vediamo la prime 5 righe del Dataframe, con il metodo **head**",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:22.083",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eAdesso che i dati sono correttamente interpretati come numerici vediamo la prime 5 righe del Dataframe, con il metodo \u003cstrong\u003ehead\u003c/strong\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574684252628_-1037328671",
      "id": "20191125-131732_633881925",
      "dateCreated": "2019-11-25 13:17:32.628",
      "dateStarted": "2019-11-27 14:13:22.123",
      "dateFinished": "2019-11-27 14:13:22.132",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.head(5)",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:22.223",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "res4: Array[org.apache.spark.sql.Row] \u003d Array([44,11], [5,190], [44,123], [9,111], [18,238])\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574683904555_-2103924770",
      "id": "20191125-131144_161534002",
      "dateCreated": "2019-11-25 13:11:44.555",
      "dateStarted": "2019-11-27 14:13:22.267",
      "dateFinished": "2019-11-27 14:13:22.583",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nVisualizziamo lo schema del DataFrame con **printSchema**, le informazioni che ottengo sono il nome e il tipo di ciascun campo:",
      "user": "anonymous",
      "dateUpdated": "2019-11-28 12:46:28.233",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eVisualizziamo lo schema del DataFrame con \u003cstrong\u003eprintSchema\u003c/strong\u003e, le informazioni che ottengo sono il nome e il tipo di ciascun campo:\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574683971968_-1817435565",
      "id": "20191125-131251_465970265",
      "dateCreated": "2019-11-25 13:12:51.968",
      "dateStarted": "2019-11-28 12:46:28.233",
      "dateFinished": "2019-11-28 12:46:28.242",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.printSchema",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:22.810",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "root\n |-- eta: integer (nullable \u003d true)\n |-- amici: integer (nullable \u003d true)\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574684617896_-327163030",
      "id": "20191125-132337_910905477",
      "dateCreated": "2019-11-25 13:23:37.896",
      "dateStarted": "2019-11-27 14:13:22.851",
      "dateFinished": "2019-11-27 14:13:23.071",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nIl Dataframe ha un numero di elementi pari a",
      "user": "anonymous",
      "dateUpdated": "2019-11-28 12:47:30.570",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eIl Dataframe ha un numero di elementi pari a\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574684852959_616214020",
      "id": "20191125-132732_1328688072",
      "dateCreated": "2019-11-25 13:27:32.959",
      "dateStarted": "2019-11-28 12:47:30.570",
      "dateFinished": "2019-11-28 12:47:30.576",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.count",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:23.292",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "res6: Long \u003d 499\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574684879292_-459614457",
      "id": "20191125-132759_1528300593",
      "dateCreated": "2019-11-25 13:27:59.292",
      "dateStarted": "2019-11-27 14:13:23.333",
      "dateFinished": "2019-11-27 14:13:23.797",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Statistica descrittiva\nCon questo termine si indica una analisi statistica da fare sui dati a disposizione.\nPer il momento usiamo semplicemente la funzione **describe()**",
      "user": "anonymous",
      "dateUpdated": "2019-11-28 12:48:38.350",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eStatistica descrittiva\u003c/h2\u003e\n\u003cp\u003eCon questo termine si indica una analisi statistica da fare sui dati a disposizione.\u003cbr/\u003ePer il momento usiamo semplicemente la funzione \u003cstrong\u003edescribe()\u003c/strong\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574689906709_1579955579",
      "id": "20191125-145146_1128384758",
      "dateCreated": "2019-11-25 14:51:46.709",
      "dateStarted": "2019-11-28 12:48:38.351",
      "dateFinished": "2019-11-28 12:48:38.366",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.describe().show",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:23.983",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------+------------------+------------------+\n|summary|               eta|             amici|\n+-------+------------------+------------------+\n|  count|               499|               499|\n|   mean| 34.78156312625251| 258.3627254509018|\n| stddev|20.532332734289348|136.55329326307273|\n|    min|                 0|                 1|\n|    max|                69|               498|\n+-------+------------------+------------------+\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574690284293_-959025520",
      "id": "20191125-145804_1966092883",
      "dateCreated": "2019-11-25 14:58:04.293",
      "dateStarted": "2019-11-27 14:13:24.020",
      "dateFinished": "2019-11-27 14:13:24.630",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Analisi\nIl problema è vedere quanti amici hanno in media le persone di un\u0027età definita x. E questo per ogni età x.\n\nFacciamo un\u0027aggregazione dei dati usando come chiave l\u0027età.\n\nPer questo ci viene in aiuto la funzione **groupBy**",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:24.723",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1574684635650_-1634697721",
      "id": "20191125-132355_452999482",
      "dateCreated": "2019-11-25 13:23:55.650",
      "dateStarted": "2019-11-27 14:13:24.771",
      "dateFinished": "2019-11-27 14:13:24.782",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.groupBy(\"eta\")",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:24.863",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "res8: org.apache.spark.sql.RelationalGroupedDataset \u003d org.apache.spark.sql.RelationalGroupedDataset@727e4c7d\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574684972834_1923654664",
      "id": "20191125-132932_1629992967",
      "dateCreated": "2019-11-25 13:29:32.834",
      "dateStarted": "2019-11-27 14:13:24.903",
      "dateFinished": "2019-11-27 14:13:25.167",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nIl metodo groupBy fornisce come risultato un **RelationalGroupedDataset**, dopodiché per utilizzarlo devo specificare come aggregare i valori corrispondenti ad ogni *key*. Per scoprire quali sono i metodi che possiamo applicare a questa entità vado sulla pagina della documentazione di Spark relativa al [RelationalGroupedDataset](https://spark.apache.org/docs/latest/api/scala/#org.apache.spark.sql.RelationalGroupedDataset). \nScopro che posso usare diverse funzioni, tra cui **agg**, **max**, **min**, **pivot**. Proviamone alcune.\n\nLa funzione min è così definita:\n    def min(colNames: String*): DataFrame",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:25.204",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eIl metodo groupBy fornisce come risultato un \u003cstrong\u003eRelationalGroupedDataset\u003c/strong\u003e, dopodiché per utilizzarlo devo specificare come aggregare i valori corrispondenti ad ogni \u003cem\u003ekey\u003c/em\u003e. Per scoprire quali sono i metodi che possiamo applicare a questa entità vado sulla pagina della documentazione di Spark relativa al \u003ca href\u003d\"https://spark.apache.org/docs/latest/api/scala/#org.apache.spark.sql.RelationalGroupedDataset\"\u003eRelationalGroupedDataset\u003c/a\u003e.\u003cbr/\u003eScopro che posso usare diverse funzioni, tra cui \u003cstrong\u003eagg\u003c/strong\u003e, \u003cstrong\u003emax\u003c/strong\u003e, \u003cstrong\u003emin\u003c/strong\u003e, \u003cstrong\u003epivot\u003c/strong\u003e. Proviamone alcune.\u003c/p\u003e\n\u003cp\u003eLa funzione min è così definita:\u003cbr/\u003e def min(colNames: String*): DataFrame\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574684984419_-762815662",
      "id": "20191125-132944_1883418827",
      "dateCreated": "2019-11-25 13:29:44.419",
      "dateStarted": "2019-11-27 14:13:25.244",
      "dateFinished": "2019-11-27 14:13:25.252",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.groupBy(\"eta\").min(\"amici\").show(5)",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:25.345",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+----------+\n|eta|min(amici)|\n+---+----------+\n| 31|        73|\n| 65|       141|\n| 53|        42|\n| 34|        53|\n| 28|        36|\n+---+----------+\nonly showing top 5 rows\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574685360866_507111509",
      "id": "20191125-133600_323730237",
      "dateCreated": "2019-11-25 13:36:00.866",
      "dateStarted": "2019-11-27 14:13:25.389",
      "dateFinished": "2019-11-27 14:13:26.577",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nAdesso voglio contare quanti elementi ci sono nel DataFrame con la stessa key, così scopro per esempio che ci sono esattamente 5 31enni.",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:26.595",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eAdesso voglio contare quanti elementi ci sono nel DataFrame con la stessa key, così scopro per esempio che ci sono esattamente 5 31enni.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574719568507_1632380477",
      "id": "20191125-230608_1242145458",
      "dateCreated": "2019-11-25 23:06:08.507",
      "dateStarted": "2019-11-27 14:13:26.704",
      "dateFinished": "2019-11-27 14:13:26.714",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.groupBy(\"eta\").count().show(5)",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:26.801",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+-----+\n|eta|count|\n+---+-----+\n| 31|    5|\n| 65|    9|\n| 53|    8|\n| 34|   10|\n| 28|    8|\n+---+-----+\nonly showing top 5 rows\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574685373281_123197630",
      "id": "20191125-133613_413840384",
      "dateCreated": "2019-11-25 13:36:13.281",
      "dateStarted": "2019-11-27 14:13:26.855",
      "dateFinished": "2019-11-27 14:13:27.808",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nPer la funzione **agg** devo specificare come argomento/i la/e funzione/i e su quale colonna ciascuna funzione deve essere applicata",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:27.860",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003ePer la funzione \u003cstrong\u003eagg\u003c/strong\u003e devo specificare come argomento/i la/e funzione/i e su quale colonna ciascuna funzione deve essere applicata\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574687171387_2080140370",
      "id": "20191125-140611_954079549",
      "dateCreated": "2019-11-25 14:06:11.387",
      "dateStarted": "2019-11-27 14:13:27.900",
      "dateFinished": "2019-11-27 14:13:27.904",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.groupBy(\"eta\").agg(count(\"amici\"),min(\"amici\"), max(\"amici\"), mean(\"amici\")).show(5)",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:27.999",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+------------+----------+----------+------------------+\n|eta|count(amici)|min(amici)|max(amici)|        avg(amici)|\n+---+------------+----------+----------+------------------+\n| 31|           5|        73|       419|             279.6|\n| 65|           9|       141|       469|328.22222222222223|\n| 53|           8|        42|       489|            322.25|\n| 34|          10|        53|       478|             278.7|\n| 28|           8|        36|       437|             249.0|\n+---+------------+----------+----------+------------------+\nonly showing top 5 rows\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574686876191_-1030045581",
      "id": "20191125-140116_2079582200",
      "dateCreated": "2019-11-25 14:01:16.191",
      "dateStarted": "2019-11-27 14:13:28.040",
      "dateFinished": "2019-11-27 14:13:29.205",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nSe volessimo sapere i dati relativi ai 30-enni potrei filtrare preventivamente usando la funzione **filter**",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:29.245",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eSe volessimo sapere i dati relativi ai 30-enni potrei filtrare preventivamente usando la funzione \u003cstrong\u003efilter\u003c/strong\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574687023957_2050611993",
      "id": "20191125-140343_1552712998",
      "dateCreated": "2019-11-25 14:03:43.958",
      "dateStarted": "2019-11-27 14:13:29.286",
      "dateFinished": "2019-11-27 14:13:29.290",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.filter(\"eta \u003d\u003d 30\").show",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:29.383",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+-----+\n|eta|amici|\n+---+-----+\n| 30|  148|\n| 30|  374|\n| 30|  153|\n| 30|  247|\n| 30|   56|\n| 30|   46|\n| 30|  352|\n+---+-----+\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574690584486_-1097583384",
      "id": "20191125-150304_609743018",
      "dateCreated": "2019-11-25 15:03:04.486",
      "dateStarted": "2019-11-27 14:13:29.424",
      "dateFinished": "2019-11-27 14:13:29.820",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nLa funzione **filter()** è del tutto equivalente alla funzione **where()**",
      "user": "anonymous",
      "dateUpdated": "2019-11-28 13:16:20.921",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eLa funzione \u003cstrong\u003efilter()\u003c/strong\u003e è del tutto equivalente alla funzione \u003cstrong\u003ewhere()\u003c/strong\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574690784980_-1550947089",
      "id": "20191125-150624_390466358",
      "dateCreated": "2019-11-25 15:06:24.980",
      "dateStarted": "2019-11-28 13:16:20.921",
      "dateFinished": "2019-11-28 13:16:20.929",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.where(\"eta \u003d\u003d 30\").show",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:30.034",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+-----+\n|eta|amici|\n+---+-----+\n| 30|  148|\n| 30|  374|\n| 30|  153|\n| 30|  247|\n| 30|   56|\n| 30|   46|\n| 30|  352|\n+---+-----+\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574690603189_661259164",
      "id": "20191125-150323_1777409381",
      "dateCreated": "2019-11-25 15:03:23.189",
      "dateStarted": "2019-11-27 14:13:30.073",
      "dateFinished": "2019-11-27 14:13:30.497",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nSe voglio aggregare i dati relativi ai 30 posso usare ancora la funzione **agg**\n",
      "user": "anonymous",
      "dateUpdated": "2019-11-28 13:18:34.037",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eSe voglio aggregare i dati relativi ai 30 posso usare ancora la funzione \u003cstrong\u003eagg\u003c/strong\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574690670332_-1102619730",
      "id": "20191125-150430_1097001603",
      "dateCreated": "2019-11-25 15:04:30.332",
      "dateStarted": "2019-11-28 13:18:34.038",
      "dateFinished": "2019-11-28 13:18:34.046",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.filter(\"eta \u003d\u003d 30\").agg(count(\"amici\"),min(\"amici\"), max(\"amici\"), mean(\"amici\")).show",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:30.723",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+------------+----------+----------+------------------+\n|count(amici)|min(amici)|max(amici)|        avg(amici)|\n+------------+----------+----------+------------------+\n|           7|        46|       374|196.57142857142858|\n+------------+----------+----------+------------------+\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574690899003_-351923275",
      "id": "20191125-150819_1600950523",
      "dateCreated": "2019-11-25 15:08:19.003",
      "dateStarted": "2019-11-27 14:13:30.764",
      "dateFinished": "2019-11-27 14:13:31.244",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nCome argomento di filter posso usare gli operatori logici di SQL",
      "user": "anonymous",
      "dateUpdated": "2019-11-28 13:19:39.238",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eCome argomento di filter posso usare gli operatori logici di SQL\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574690921240_-2055593804",
      "id": "20191125-150841_31200003",
      "dateCreated": "2019-11-25 15:08:41.240",
      "dateStarted": "2019-11-28 13:19:39.238",
      "dateFinished": "2019-11-28 13:19:39.246",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.filter(\"eta\u003e\u003d30 AND eta\u003c\u003d32\").agg(count(\"amici\"),min(\"amici\"), max(\"amici\"), mean(\"amici\")).show",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:31.422",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+------------+----------+----------+------------------+\n|count(amici)|min(amici)|max(amici)|        avg(amici)|\n+------------+----------+----------+------------------+\n|          13|        46|       419|232.84615384615384|\n+------------+----------+----------+------------------+\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574691035951_-361650596",
      "id": "20191125-151035_686521832",
      "dateCreated": "2019-11-25 15:10:35.951",
      "dateStarted": "2019-11-27 14:13:31.459",
      "dateFinished": "2019-11-27 14:13:31.840",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nVediamo di calcolare per ogni età il delta tra il numero massimo di amici e il numero minimo.\nNel codice sotto, ho fatto un groupBy(\"eta\"), con funzioni aggreganti **min** e **max**.\n\nDopodiché con il metodo **withColumnRenamed** ho rinominato le due colonne poiché non riesco ad usare i nomi di default (min(amici) e max(amici)).\n\nInfine con la funzione **select** ho selezionato le colonne che mi interessano e ho definito una nuova colonna come (\u0027maxAmici - \u0027minAmici). \n\nSi noti che ho usato due diverse notazioni possibili per indicare il nome della colonna: **\u0027nome-colonna**  oppure  **\"nome-colonna\"**.",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:31.859",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eVediamo di calcolare per ogni età il delta tra il numero massimo di amici e il numero minimo.\u003cbr/\u003eNel codice sotto, ho fatto un groupBy(\u0026ldquo;eta\u0026rdquo;), con funzioni aggreganti \u003cstrong\u003emin\u003c/strong\u003e e \u003cstrong\u003emax\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eDopodiché con il metodo \u003cstrong\u003ewithColumnRenamed\u003c/strong\u003e ho rinominato le due colonne poiché non riesco ad usare i nomi di default (min(amici) e max(amici)).\u003c/p\u003e\n\u003cp\u003eInfine con la funzione \u003cstrong\u003eselect\u003c/strong\u003e ho selezionato le colonne che mi interessano e ho definito una nuova colonna come (\u0026rsquo;maxAmici - \u0026rsquo;minAmici). \u003c/p\u003e\n\u003cp\u003eSi noti che ho usato due diverse notazioni possibili per indicare il nome della colonna: \u003cstrong\u003e\u0026rsquo;nome-colonna\u003c/strong\u003e oppure \u003cstrong\u003e\u0026ldquo;nome-colonna\u0026rdquo;\u003c/strong\u003e.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574692870970_-1722637644",
      "id": "20191125-154110_117346726",
      "dateCreated": "2019-11-25 15:41:10.970",
      "dateStarted": "2019-11-27 14:13:31.911",
      "dateFinished": "2019-11-27 14:13:31.920",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val df2 \u003d df.groupBy(\"eta\").agg(min(\u0027amici), max(\u0027amici))\n\nval df3 \u003d df2.withColumnRenamed(\"min(amici)\", \"minAmici\").withColumnRenamed(\"max(amici)\", \"maxAmici\")\n\ndf3.select(\u0027eta, \u0027minAmici, \u0027maxAmici, (\u0027maxAmici - \u0027minAmici) as (\"delta\")).show(5)",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:32.012",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+--------+--------+-----+\n|eta|minAmici|maxAmici|delta|\n+---+--------+--------+-----+\n| 31|      73|     419|  346|\n| 65|     141|     469|  328|\n| 53|      42|     489|  447|\n| 34|      53|     478|  425|\n| 28|      36|     437|  401|\n+---+--------+--------+-----+\nonly showing top 5 rows\n\r\ndf2: org.apache.spark.sql.DataFrame \u003d [eta: int, min(amici): int ... 1 more field]\r\ndf3: org.apache.spark.sql.DataFrame \u003d [eta: int, minAmici: int ... 1 more field]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574696411492_826493343",
      "id": "20191125-164011_184046025",
      "dateCreated": "2019-11-25 16:40:11.492",
      "dateStarted": "2019-11-27 14:13:32.057",
      "dateFinished": "2019-11-27 14:13:33.148",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nUn altro modo per esprimere l\u0027ultima riga del codice sopra è usando il metodo **selectExpr**.\nCon l\u0027argomento **\"*\"** indico che voglio tutte le righe del DataFrame originario.\nE poi definisco tra virgolette la nuova colonna come differenze tra le atre due colonne maxAmici e minAmici.\n\nLa grossa differenza con select è che selectExpr consente di usare espressioni SQL.",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:33.162",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eUn altro modo per esprimere l\u0026rsquo;ultima riga del codice sopra è usando il metodo \u003cstrong\u003eselectExpr\u003c/strong\u003e.\u003cbr/\u003eCon l\u0026rsquo;argomento \u003cstrong\u003e\u0026quot;*\u0026quot;\u003c/strong\u003e indico che voglio tutte le righe del DataFrame originario.\u003cbr/\u003eE poi definisco tra virgolette la nuova colonna come differenze tra le atre due colonne maxAmici e minAmici.\u003c/p\u003e\n\u003cp\u003eLa grossa differenza con select è che selectExpr consente di usare espressioni SQL.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574697960185_-466029341",
      "id": "20191125-170600_1839550777",
      "dateCreated": "2019-11-25 17:06:00.185",
      "dateStarted": "2019-11-27 14:13:33.209",
      "dateFinished": "2019-11-27 14:13:33.215",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df3.selectExpr( \"*\", \"(maxAmici - minAmici) as delta\" ).show(5)",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:33.310",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+--------+--------+-----+\n|eta|minAmici|maxAmici|delta|\n+---+--------+--------+-----+\n| 31|      73|     419|  346|\n| 65|     141|     469|  328|\n| 53|      42|     489|  447|\n| 34|      53|     478|  425|\n| 28|      36|     437|  401|\n+---+--------+--------+-----+\nonly showing top 5 rows\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574697505646_-2043094092",
      "id": "20191125-165825_1385459195",
      "dateCreated": "2019-11-25 16:58:25.646",
      "dateStarted": "2019-11-27 14:13:33.346",
      "dateFinished": "2019-11-27 14:13:33.904",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nA quale età si hanno in media più amici? Utilizziamo la funzione **sort()** con la specifica **.desc**",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:33.949",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eA quale età si hanno in media più amici? Utilizziamo la funzione \u003cstrong\u003esort()\u003c/strong\u003e con la specifica \u003cstrong\u003e.desc\u003c/strong\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574697503471_1491429497",
      "id": "20191125-165823_548995766",
      "dateCreated": "2019-11-25 16:58:23.471",
      "dateStarted": "2019-11-27 14:13:33.983",
      "dateFinished": "2019-11-27 14:13:33.987",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.groupBy(\"eta\").mean(\"amici\").withColumnRenamed(\"avg(amici)\", \"avgAmici\").sort(\u0027avgAmici.desc).show(5)",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:34.083",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+-----------------+\n|eta|         avgAmici|\n+---+-----------------+\n|  6|394.3333333333333|\n| 56|366.3333333333333|\n| 40|           344.25|\n| 12|339.6666666666667|\n| 21|            336.9|\n+---+-----------------+\nonly showing top 5 rows\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574697502477_-1354601554",
      "id": "20191125-165822_142643538",
      "dateCreated": "2019-11-25 16:58:22.477",
      "dateStarted": "2019-11-27 14:13:34.121",
      "dateFinished": "2019-11-27 14:13:35.645",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nSe voglio creare un nuovo DataFrame con le prime N righe dopo avere ordinato la colonna in ordine decrescente uso la funzione **limit(N)**",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:35.725",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eSe voglio creare un nuovo DataFrame con le prime N righe dopo avere ordinato la colonna in ordine decrescente uso la funzione \u003cstrong\u003elimit(N)\u003c/strong\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574696035991_930948805",
      "id": "20191125-163355_1989865449",
      "dateCreated": "2019-11-25 16:33:55.991",
      "dateStarted": "2019-11-27 14:13:35.764",
      "dateFinished": "2019-11-27 14:13:35.768",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df.groupBy(\"eta\").mean(\"amici\").withColumnRenamed(\"avg(amici)\", \"avgAmici\").sort(\u0027avgAmici.desc).limit(10).show()",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:35.865",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+------------------+\n|eta|          avgAmici|\n+---+------------------+\n|  6| 394.3333333333333|\n| 56| 366.3333333333333|\n| 40|            344.25|\n| 12| 339.6666666666667|\n| 21|             336.9|\n| 50|             332.4|\n| 65|328.22222222222223|\n| 53|            322.25|\n|  1|             321.6|\n| 37|             320.6|\n+---+------------------+\n\r\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574696224717_426264717",
      "id": "20191125-163704_1449211607",
      "dateCreated": "2019-11-25 16:37:04.717",
      "dateStarted": "2019-11-27 14:13:35.904",
      "dateFinished": "2019-11-27 14:13:37.068",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nAggiungere una riga al DataFrame non è immediato, in quanto occorre creare un nuovo DataFrame con una riga e successivamente fare l\u0027unione dei due DataFrame.\n\nPer creare il nuovo DataFrame uso il metodo della SparkSession **createDataFrame**, che prende come argomenti un RDD composto da Row, e lo *schema* da seguire, per questo uso lo schema di df.\n",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:37.108",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eAggiungere una riga al DataFrame non è immediato, in quanto occorre creare un nuovo DataFrame con una riga e successivamente fare l\u0026rsquo;unione dei due DataFrame.\u003c/p\u003e\n\u003cp\u003ePer creare il nuovo DataFrame uso il metodo della SparkSession \u003cstrong\u003ecreateDataFrame\u003c/strong\u003e, che prende come argomenti un RDD composto da Row, e lo \u003cem\u003eschema\u003c/em\u003e da seguire, per questo uso lo schema di df.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574707530775_346237677",
      "id": "20191125-194530_851574778",
      "dateCreated": "2019-11-25 19:45:30.775",
      "dateStarted": "2019-11-27 14:13:37.145",
      "dateFinished": "2019-11-27 14:13:37.150",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "//filtriamo gli elementi con età 31 anni\nval df2 \u003d df.filter(\"eta \u003d\u003d 31\")\ndf2.show\n//importo il tipo Row\nimport org.apache.spark.sql.Row\n//creo un RDD di Row\nval dataRDD \u003d spark.sparkContext.parallelize(Seq(Row(31,100)))\n//creo il nuovo DataFrame\nval newdf \u003d spark.createDataFrame(dataRDD, df.schema)\nval df_31 \u003d df2.union(newdf)\ndf_31.show",
      "user": "anonymous",
      "dateUpdated": "2019-11-27 14:13:37.244",
      "config": {
        "colWidth": 12.0,
        "fontSize": 9.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+-----+\n|eta|amici|\n+---+-----+\n| 31|  172|\n| 31|  408|\n| 31|   73|\n| 31|  326|\n| 31|  419|\n+---+-----+\n\r\n+---+-----+\n|eta|amici|\n+---+-----+\n| 31|  172|\n| 31|  408|\n| 31|   73|\n| 31|  326|\n| 31|  419|\n| 31|  100|\n+---+-----+\n\r\ndf2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [eta: int, amici: int]\r\nimport org.apache.spark.sql.Row\r\ndataRDD: org.apache.spark.rdd.RDD[org.apache.spark.sql.Row] \u003d ParallelCollectionRDD[96] at parallelize at \u003cconsole\u003e:37\r\nnewdf: org.apache.spark.sql.DataFrame \u003d [eta: int, amici: int]\r\ndf_31: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [eta: int, amici: int]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1574707969498_-1703321839",
      "id": "20191125-195249_1016619002",
      "dateCreated": "2019-11-25 19:52:49.498",
      "dateStarted": "2019-11-27 14:13:37.292",
      "dateFinished": "2019-11-27 14:13:37.974",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Spark DataFrame Basic 1",
  "id": "2ET6N23G8",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}